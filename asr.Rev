print("starting script")
system("date")
# load file with gene families to read
system("cat /home/dsellis/data/IES/analysis/asr/geneFamilies.dat > /home/dsellis/data/IES/analysis/asr/geneFamilies1.dat")
#pick random 100 files
#shuf -n 100
#system("shuf -n 500 /home/dsellis/data/IES/analysis/asr/geneFamilies.dat > /home/dsellis/data/IES/analysis/asr/geneFamilies1.dat")
#system("head -n 100 /home/dsellis/data/IES/analysis/asr/geneFamilies.dat > /home/dsellis/data/IES/analysis/asr/geneFamilies1.dat")
#system("echo 3 > /home/dsellis/data/IES/analysis/asr/geneFamilies1.dat")
    
geneFamilies = readCharacterDataDelimited(file = "/home/dsellis/data/IES/analysis/asr/geneFamilies1.dat", type = "Standard", delimiter = "\t")
geneFamilyNames = geneFamilies.names()
for(i in 1:geneFamilyNames.size()){
  clusterS = geneFamilies.names()[i].getSpeciesName()
  if(clusterS == "2825" || clusterS == "10007" || clusterS == "5033" || clusterS == "11561" || clusterS == "14273" || clusterS == "15227"){    # skip families with low starting probabilities
  }else{
    data[i] = readDiscreteCharacterData("/home/dsellis/data/IES/analysis/asr/charMat"+ clusterS + ".nexus")
    psi[i] = readTrees("/home/dsellis/data/IES/analysis/asr/tree" + clusterS + ".nexus")[1]  
#OPTLINE   write(psi[i], filename = "rbNodeIndexesP/nodeIndex." + clusterS + ".tre") # save file with trees and node indexes
  }
}
#setOption("scalingDensity", 1) #scale at every node!

# rates of change
alpha ~ dnExponential(1)
insertionRate ~ dnExponential(alpha)
lossRate ~ dnExponential(alpha)

mi <- 0
moves[mi++] = mvScale(alpha, lambda = 1)
# moves[mi++] = mvScale(alpha, lambda = 0.1)
# moves[mi++] = mvScale(alpha, lambda = 0.01)

#this gives equal rates
Q := fnFreeBinary([insertionRate, lossRate])

# a hierarchy of scale moves
moves[mi++] = mvScale(insertionRate, lambda = 1) #default
moves[mi++] = mvScale(lossRate, lambda = 1)

# moves[mi++] = mvScale(insertionRate, lambda = 0.1)
# moves[mi++] = mvScale(lossRate, lambda = 0.1)

# moves[mi++] = mvScale(insertionRate, lambda = 0.01)
# moves[mi++] = mvScale(lossRate, lambda = 0.01)

print("making models")
system("date")
for(i in 1:geneFamilyNames.size()){
  system("printf 'making model "+ i + " out of " + geneFamilyNames.size() + "\r'")
  ctmc[i] ~ dnPhyloCTMC(Q = Q, tree = psi[i], type = "Restriction", coding = "noabsencesites")
#  ctmc[i] ~ dnPhyloCTMC(Q = Q, tree = psi[i], type = "Standard")
  ctmc[i].clamp(data[i])
}

#coding = [noabsencesites|all(default)]
#type =[restriction]

mymodel = model(ctmc)
print("adding monitors")
system("date")
for(i in 1:geneFamilyNames.size()){
  system("printf 'adding model "+ i + " out of " + geneFamilyNames.size() + "\r'")
  clusterS = geneFamilies.names()[i].getSpeciesName()
  monitors[i] = mnJointConditionalAncestralState(tree = psi[i], ctmc = ctmc[i], filename = "OUTPATH/ancStates" + clusterS + ".log", type = "Restriction", printgen = 100, withStartStates = false)
# withStartStates = false does not print both start and end states for each node
}

monitors[++i] = mnFile(filename = "OUTPATH/parameters1.log", insertionRate, lossRate, alpha, likelihood = true, printgen=100)
monitors[++i] = mnScreen(insertionRate, lossRate, printgen=1000)

mymcmc = mcmc(mymodel, monitors, moves)
mymcmc.burnin(generations=10000,tuningInterval=1000)
mymcmc.run(1000000)
#mymcmc.run(10000)
quit()


